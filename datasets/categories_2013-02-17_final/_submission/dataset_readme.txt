This dataset contains each Wikipedia article associated with a list of 940,017 people from Freebase which existed in both English and Spanish Wikipedia with a readable prose size of at least 2 kilobytes: a total of 52,162 articles in each language.

There is one file per language (en-article-topics-full.tsv for English, and es-article-topics-full.tsv for Spanish). The first row of each file indicates which topic name is associated with each column. There is one line per article, starting with the second line. The first column is the article name, followed by the share of each topic. Columns are separated by tabs.

Details of Data Preprocessing:

We first prepared the text by performing lemmatization (with NLTK's WordNet lemmatizer for English and FreeLing for Spanish). Then, we cleaned the text as follows. We removed named entities by removing all capitalized words (English), and words identified as named entities by FreeLing (Spanish), as Spanish does not capitalize all proper nouns as English does. The rationale behind removing all capitalized English words instead of performing named entity recognition was that false positives did not matter due to the large size of the corpus, but false negatives could skew the results. In addition, we removed words with fewer than three letters, symbols, numbers, and stop words. We used NLTK's list of English stop words, and supplemented its Spanish stop word list with entries from the stop-words Google Code project. Finally, we converted British English spelling to American English spelling. 

We broke down the article contents into 30 separate topics by using Latent Dirichlet Allocation (LDA), a  generative model for unsupervised topic modeling that finds clusters of similar words. We used the collapsed Gibbs sampling implementation of LDA in Mallet, a Java-based package for statistical NLP. We split the article corpus in each language into three non-overlapping subsamples to run a 3-fold cross-validation, which we repeated three times. For each of the three runs of cross-validation, we trained the topic model separately on each combination of two folds of articles and performed topic inference on the held-out fold of articles. When training the topic model, we fit LDA with 30 topics using 5000 iterations of Gibbs sampling with hyper parameter optimization every 10 iterations. Then, to perform topic inference, we used the already-trained model to infer topics for the new, held-out This identified the topics mentioned in each article and the fraction of the article devoted to them. documents. Since we used two subsamples of each fold to classify the third, each of the three runs identified article topic composition for the entire corpus. We then labelled the 30 topics found for each of the 18 training iterations (three separate iterations of three-fold cross validation for both English and Spanish) using human classifiers, according to the top 100 words of each topic. We hand-matched the topics across the three runs, and averaged the per-article results of all three runs to get the topic composition of each article. 

Topic Labels:

Of the 30 topics, we identified 16 with a clear common denominator and labeled them as follows: Art, Business and Economics, Education and Academia, Explorers, Humanities and Social Sciences, Law and Crime, Literature, Media, (including TV, film, and popular culture items such as reality shows and celebrity news), Music, Personal Life, Politics and Government, Religion (mostly Catholicism), Royalty, Science and Technology, Sports, and Warfare and Military. All 16 topics appear in both languages, and the words associated with each topic were very similar across languages.

Mapping from Topics to Wikipedia Featured Article Categories:

Most of the topics we labeled can be mapped to the categories used by the English and Spanish Wikipedias to classify featured articles; these categories are manually determined by Wikipedia contributors.  The two exceptions are Personal Life, which describes stages in life and relationships, and Explorers, which is mostly about voyages and geographical discoveries. At the same time, the Wikipedia categories of History and "Culture and Society", which appear in both English and Spanish, do not have matching topics in our model. It is worth noting that these two categories are very general: they contain articles about Julius Caesar, Eva Per\'{o}n, and W. E. B. Du Bois, and they seem like default categories for articles who could not be easily classified into one of the other categories. The English Wikipedia contains two additional categories that did not emerge in our LDA modeling, "Food and Drink" and Transport, and did not appear in the Spanish Wikipedia either. However, these two categories only hold five articles combined. (The explicit table of category mappings is given in category-mapping-table.pdf)
