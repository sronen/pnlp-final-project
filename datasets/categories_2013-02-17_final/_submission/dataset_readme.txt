Strucuture:

file per language

Row per article

First column is the article name, followed by the share of each topic. 

--- ADD: table of top 10 words for each category.

We broke down the article contents into 30 separate topics by using \emph{latent Dirichlet allocation} (LDA), a  generative model for unsupervised topic modeling that finds words that are more strongly associated with each other, and clusters them into topics ~\cite{blei_2003}. We used the Gibbs sampling implementation of LDA in Mallet ~\cite{mccallum_2002}, a Java-based package for statistical NLP. We split the article corpus in each language into three non-overlapping subsamples to run a 3-fold cross-validation \cite{kokhavi_1995}, which we repeated three times. For each of the three runs of cross-validation, we trained the topic model separately on each combination of two folds of articles and performed topic inference on the held-out fold of articles. When training the topic model, we fit LDA with 30 topics using 5000 iterations of Gibbs sampling with hyper parameter optimization every 10 iterations. Then, to perform topic inference, we used the already-trained model to infer topics for the new, held-out This identified the topics mentioned in each article and the fraction of the article devoted to them. documents. Since we used two subsamples of each fold to classify the third, each of the three runs identified article topic composition for the entire corpus. We then labelled the 30 topics found for each of the 18 training iterations (three separate iterations of three-fold cross validation for both English and Spanish) using human classifiers, according to the top 100 words of each topic (Table~\ref{top-ten-words-for-topic-table} shows a partial list). We hand-matched the topics across the three runs, and averaged the per-article results of all three runs to get the topic composition of each article. 

Of the 30 topics, we identified 16 with a clear common denominator and labeled them as follows: \emph{Art, Business and Economics, Education and Academia, Explorers, Humanities and Social Sciences, Law and Crime, Literature, Media} (including TV, film, and popular culture items such as reality shows and celebrity news), \emph{Music, Personal Life, Politics and Government, Religion} (mostly Catholicism), \emph{Royalty, Science and Technology, Sports,} and \emph{Warfare and Military}. All 16 topics appear in both languages, and the words associated with each topic were very similar across languages. Most of the topics we labeled can be mapped to the categories used by the English and Spanish Wikipedias to classify featured articles; these categories are manually determined by Wikipedia contributors.  The two exceptions  are \emph{personal life}, which describes stages in life and relationships, and \emph{explorers}, which is mostly about voyages and geographical discoveries. At the same time, the Wikipedia categories of \emph{history} and \emph{culture and society}, which appear in both English and Spanish, do not have matching topics in our model. It is worth noting that these two categories are very general: they contain articles about Julius Caesar, Eva Per\'{o}n, and W. E. B. Du Bois, and they seem like default categories for articles who could not be easily classified into one of the other categories. The English Wikipedia contains two additional categories that did not emerge in our LDA modeling, \emph{food and drink} and \emph{transport}, and did not appear in the Spanish Wikipedia either. However, these two categories only hold five articles combined.
